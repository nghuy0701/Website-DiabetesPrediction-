{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4ebefe6",
   "metadata": {},
   "source": [
    "# üè• Diabetes Prediction Model Training Pipeline\n",
    "## M·ª•c ti√™u:\n",
    "- Hu·∫•n luy·ªán nhi·ªÅu m√¥ h√¨nh ML kh√°c nhau\n",
    "- So s√°nh hi·ªáu su·∫•t c·ªßa c√°c m√¥ h√¨nh\n",
    "- T·ªëi ∆∞u h√≥a hyperparameters\n",
    "- Ch·ªçn ra m√¥ h√¨nh t·ªët nh·∫•t cho production\n",
    "\n",
    "## Dataset:\n",
    "S·ª≠ d·ª•ng Pima Indians Diabetes Dataset v·ªõi 8 features ch√≠nh:\n",
    "- **Pregnancies**: S·ªë l·∫ßn mang thai\n",
    "- **Glucose**: N·ªìng ƒë·ªô glucose trong m√°u\n",
    "- **BloodPressure**: Huy·∫øt √°p t√¢m tr∆∞∆°ng\n",
    "- **SkinThickness**: ƒê·ªô d√†y n·∫øp g·∫•p da c√°nh tay\n",
    "- **Insulin**: N·ªìng ƒë·ªô insulin trong m√°u\n",
    "- **BMI**: Ch·ªâ s·ªë kh·ªëi c∆° th·ªÉ\n",
    "- **DiabetesPedigreeFunction**: H√†m di truy·ªÅn ti·ªÉu ƒë∆∞·ªùng\n",
    "- **Age**: Tu·ªïi\n",
    "\n",
    "**Target**: Outcome (0: Kh√¥ng m·∫Øc ti·ªÉu ƒë∆∞·ªùng, 1: M·∫Øc ti·ªÉu ƒë∆∞·ªùng)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef30b77c",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries\n",
    "\n",
    "Import t·∫•t c·∫£ c√°c th∆∞ vi·ªán c·∫ßn thi·∫øt cho machine learning pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "593535c5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Data manipulation and analysis\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mwarnings\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "# Data manipulation and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Scikit-learn libraries\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split, cross_val_score, GridSearchCV, \n",
    "    RandomizedSearchCV, StratifiedKFold\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, confusion_matrix, classification_report,\n",
    "    roc_curve, precision_recall_curve, average_precision_score\n",
    ")\n",
    "\n",
    "# Machine Learning Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier, GradientBoostingClassifier, \n",
    "    AdaBoostClassifier, ExtraTreesClassifier\n",
    ")\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Advanced ML libraries (c√†i ƒë·∫∑t n·∫øu c·∫ßn: pip install xgboost lightgbm catboost)\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "    print(\"‚úÖ XGBoost available\")\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è XGBoost not available. Install: pip install xgboost\")\n",
    "    xgb = None\n",
    "\n",
    "try:\n",
    "    import lightgbm as lgb\n",
    "    print(\"‚úÖ LightGBM available\")\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è LightGBM not available. Install: pip install lightgbm\")\n",
    "    lgb = None\n",
    "\n",
    "try:\n",
    "    from catboost import CatBoostClassifier\n",
    "    print(\"‚úÖ CatBoost available\")\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è CatBoost not available. Install: pip install catboost\")\n",
    "    CatBoostClassifier = None\n",
    "\n",
    "# Imbalanced learning (c√†i ƒë·∫∑t n·∫øu c·∫ßn: pip install imbalanced-learn)\n",
    "try:\n",
    "    from imblearn.over_sampling import SMOTE, ADASYN\n",
    "    from imblearn.under_sampling import RandomUnderSampler\n",
    "    from imblearn.combine import SMOTEENN\n",
    "    print(\"‚úÖ Imbalanced-learn available\")\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è Imbalanced-learn not available. Install: pip install imbalanced-learn\")\n",
    "    SMOTE = ADASYN = RandomUnderSampler = SMOTEENN = None\n",
    "\n",
    "# Utility libraries\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"üì¶ All libraries imported successfully!\")\n",
    "print(f\"üìä Using pandas: {pd.__version__}\")\n",
    "print(f\"üî¢ Using numpy: {np.__version__}\")\n",
    "print(f\"ü§ñ Using scikit-learn: {sklearn.__version__}\" if 'sklearn' in locals() else \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a65202",
   "metadata": {},
   "source": [
    "## 2. Load and Explore Cleaned Dataset\n",
    "\n",
    "Load d·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c l√†m s·∫°ch v√† th·ª±c hi·ªán ph√¢n t√≠ch kh√°m ph√° (EDA) ƒë·ªÉ hi·ªÉu r√µ v·ªÅ dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92ea70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load cleaned dataset\n",
    "DATA_PATH = \"../data/pima_clean.csv\"\n",
    "\n",
    "print(\"üìÇ Loading Pima Indians Diabetes Dataset...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "try:\n",
    "    # Load the cleaned dataset\n",
    "    df = pd.read_csv(DATA_PATH)\n",
    "    print(f\"‚úÖ Successfully loaded data from {DATA_PATH}\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(f\"‚ùå File not found: {DATA_PATH}\")\n",
    "    print(\"Please ensure the dataset is in the correct location.\")\n",
    "    raise\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading data: {e}\")\n",
    "    raise\n",
    "\n",
    "# Display basic information\n",
    "print(f\"\\nüìä Dataset Info:\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"Rows: {df.shape[0]}\")\n",
    "print(f\"Columns: {df.shape[1]}\")\n",
    "\n",
    "print(f\"\\nüìã Column Names:\")\n",
    "print(df.columns.tolist())\n",
    "\n",
    "print(f\"\\nüéØ Target Variable:\")\n",
    "if 'Outcome' in df.columns:\n",
    "    print(\"‚úÖ 'Outcome' column found\")\n",
    "    print(f\"Values: {df['Outcome'].unique()}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  'Outcome' column not found. Available columns:\", df.columns.tolist())\n",
    "\n",
    "# Display first few rows\n",
    "print(f\"\\nüìã First 5 rows of dataset:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f616bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic data exploration\n",
    "print(\"üîç DATASET OVERVIEW\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(f\"\\nüìä Basic Statistics:\")\n",
    "print(df.describe())\n",
    "\n",
    "print(f\"\\nüéØ Target Distribution:\")\n",
    "target_counts = df['Outcome'].value_counts()\n",
    "target_percentages = df['Outcome'].value_counts(normalize=True) * 100\n",
    "\n",
    "print(f\"No Diabetes (0): {target_counts[0]} samples ({target_percentages[0]:.1f}%)\")\n",
    "print(f\"Diabetes (1): {target_counts[1]} samples ({target_percentages[1]:.1f}%)\")\n",
    "\n",
    "print(f\"\\n‚ùì Missing Values:\")\n",
    "missing_values = df.isnull().sum()\n",
    "if missing_values.sum() == 0:\n",
    "    print(\"‚úÖ No missing values found\")\n",
    "else:\n",
    "    print(missing_values[missing_values > 0])\n",
    "\n",
    "print(f\"\\nüî¢ Data Types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# Check for duplicate rows\n",
    "duplicates = df.duplicated().sum()\n",
    "print(f\"\\nüîÑ Duplicate rows: {duplicates}\")\n",
    "\n",
    "if duplicates > 0:\n",
    "    print(\"Removing duplicate rows...\")\n",
    "    df = df.drop_duplicates()\n",
    "    print(f\"‚úÖ Removed {duplicates} duplicate rows. New shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad88fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizations\n",
    "print(\"üìä VISUALIZATIONS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Create subplots for comprehensive visualization\n",
    "fig = make_subplots(\n",
    "    rows=3, cols=3,\n",
    "    subplot_titles=[\n",
    "        'Target Distribution', 'Age Distribution by Outcome', 'BMI Distribution by Outcome',\n",
    "        'Glucose Distribution by Outcome', 'Correlation Heatmap', 'Pregnancies vs Outcome',\n",
    "        'Blood Pressure Distribution', 'Insulin Distribution', 'Feature Box Plots'\n",
    "    ],\n",
    "    specs=[[{\"type\": \"bar\"}, {\"type\": \"histogram\"}, {\"type\": \"histogram\"}],\n",
    "           [{\"type\": \"histogram\"}, {\"type\": \"heatmap\"}, {\"type\": \"box\"}],\n",
    "           [{\"type\": \"histogram\"}, {\"type\": \"histogram\"}, {\"type\": \"box\"}]]\n",
    ")\n",
    "\n",
    "# 1. Target distribution\n",
    "target_counts = df['Outcome'].value_counts()\n",
    "fig.add_trace(\n",
    "    go.Bar(x=['No Diabetes', 'Diabetes'], y=target_counts.values, \n",
    "           marker_color=['skyblue', 'lightcoral']),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# 2. Age distribution by outcome\n",
    "for outcome in [0, 1]:\n",
    "    fig.add_trace(\n",
    "        go.Histogram(x=df[df['Outcome']==outcome]['Age'], \n",
    "                    name=f'Outcome {outcome}', opacity=0.7),\n",
    "        row=1, col=2\n",
    "    )\n",
    "\n",
    "# 3. BMI distribution by outcome\n",
    "for outcome in [0, 1]:\n",
    "    fig.add_trace(\n",
    "        go.Histogram(x=df[df['Outcome']==outcome]['BMI'], \n",
    "                    name=f'BMI Outcome {outcome}', opacity=0.7),\n",
    "        row=1, col=3\n",
    "    )\n",
    "\n",
    "# 4. Glucose distribution by outcome\n",
    "for outcome in [0, 1]:\n",
    "    fig.add_trace(\n",
    "        go.Histogram(x=df[df['Outcome']==outcome]['Glucose'], \n",
    "                    name=f'Glucose Outcome {outcome}', opacity=0.7),\n",
    "        row=2, col=1\n",
    "    )\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(height=1200, title_text=\"Diabetes Dataset - Comprehensive Analysis\")\n",
    "fig.show()\n",
    "\n",
    "# Separate correlation heatmap using matplotlib/seaborn for better control\n",
    "plt.figure(figsize=(12, 8))\n",
    "correlation_matrix = df.corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0,\n",
    "            square=True, linewidths=0.5, fmt='.2f')\n",
    "plt.title('üîó Feature Correlation Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Feature distributions by outcome\n",
    "feature_cols = [col for col in df.columns if col != 'Outcome']\n",
    "n_features = len(feature_cols)\n",
    "n_cols = 3\n",
    "n_rows = (n_features + n_cols - 1) // n_cols\n",
    "\n",
    "plt.figure(figsize=(15, 5 * n_rows))\n",
    "for i, feature in enumerate(feature_cols, 1):\n",
    "    plt.subplot(n_rows, n_cols, i)\n",
    "    \n",
    "    # Create histograms for both outcomes\n",
    "    df[df['Outcome']==0][feature].hist(alpha=0.7, bins=30, label='No Diabetes', color='skyblue')\n",
    "    df[df['Outcome']==1][feature].hist(alpha=0.7, bins=30, label='Diabetes', color='lightcoral')\n",
    "    \n",
    "    plt.title(f'{feature} Distribution by Outcome')\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Visualization completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d29889d",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering and Selection\n",
    "\n",
    "Chu·∫©n b·ªã features cho machine learning bao g·ªìm scaling, encoding v√† feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5508d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle zero values (potential missing values in medical data)\n",
    "print(\"üîß FEATURE ENGINEERING\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Features that shouldn't have zero values in medical context\n",
    "zero_not_accepted = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']\n",
    "\n",
    "print(\"\\nüîç Checking for zero values (potential missing data):\")\n",
    "df_processed = df.copy()\n",
    "\n",
    "for feature in zero_not_accepted:\n",
    "    if feature in df_processed.columns:\n",
    "        zero_count = (df_processed[feature] == 0).sum()\n",
    "        zero_percentage = (zero_count / len(df_processed)) * 100\n",
    "        \n",
    "        if zero_count > 0:\n",
    "            print(f\"{feature}: {zero_count} zeros ({zero_percentage:.1f}%)\")\n",
    "            \n",
    "            # Replace zeros with median of non-zero values\n",
    "            median_value = df_processed[df_processed[feature] != 0][feature].median()\n",
    "            df_processed[feature] = df_processed[feature].replace(0, median_value)\n",
    "            print(f\"  ‚Üí Replaced with median: {median_value:.2f}\")\n",
    "        else:\n",
    "            print(f\"{feature}: ‚úÖ No zero values\")\n",
    "\n",
    "print(f\"\\nüìä Dataset shape after preprocessing: {df_processed.shape}\")\n",
    "\n",
    "# Create new features (Feature Engineering)\n",
    "print(\"\\nüõ†Ô∏è Creating new features:\")\n",
    "\n",
    "# 1. BMI Categories\n",
    "df_processed['BMI_Category'] = pd.cut(df_processed['BMI'], \n",
    "                                    bins=[0, 18.5, 25, 30, 100], \n",
    "                                    labels=['Underweight', 'Normal', 'Overweight', 'Obese'])\n",
    "\n",
    "# Convert categorical to numerical\n",
    "bmi_mapping = {'Underweight': 0, 'Normal': 1, 'Overweight': 2, 'Obese': 3}\n",
    "df_processed['BMI_Category_Num'] = df_processed['BMI_Category'].map(bmi_mapping)\n",
    "\n",
    "# 2. Age Groups\n",
    "df_processed['Age_Group'] = pd.cut(df_processed['Age'], \n",
    "                                 bins=[0, 30, 40, 50, 100], \n",
    "                                 labels=['Young', 'Adult', 'Middle', 'Senior'])\n",
    "\n",
    "age_mapping = {'Young': 0, 'Adult': 1, 'Middle': 2, 'Senior': 3}\n",
    "df_processed['Age_Group_Num'] = df_processed['Age_Group'].map(age_mapping)\n",
    "\n",
    "# 3. Glucose Categories (based on medical standards)\n",
    "df_processed['Glucose_Category'] = pd.cut(df_processed['Glucose'], \n",
    "                                        bins=[0, 100, 126, 200], \n",
    "                                        labels=['Normal', 'Prediabetic', 'Diabetic'])\n",
    "\n",
    "glucose_mapping = {'Normal': 0, 'Prediabetic': 1, 'Diabetic': 2}\n",
    "df_processed['Glucose_Category_Num'] = df_processed['Glucose_Category'].map(glucose_mapping)\n",
    "\n",
    "# 4. Blood Pressure Categories\n",
    "df_processed['BP_Category'] = pd.cut(df_processed['BloodPressure'], \n",
    "                                   bins=[0, 80, 90, 140], \n",
    "                                   labels=['Normal', 'High_Normal', 'High'])\n",
    "\n",
    "bp_mapping = {'Normal': 0, 'High_Normal': 1, 'High': 2}\n",
    "df_processed['BP_Category_Num'] = df_processed['BP_Category'].map(bp_mapping)\n",
    "\n",
    "# 5. Risk Score (combination of multiple factors)\n",
    "# Normalize features to 0-1 scale for risk calculation\n",
    "risk_features = ['Glucose', 'BMI', 'Age', 'BloodPressure']\n",
    "for feature in risk_features:\n",
    "    min_val = df_processed[feature].min()\n",
    "    max_val = df_processed[feature].max()\n",
    "    df_processed[f'{feature}_Normalized'] = (df_processed[feature] - min_val) / (max_val - min_val)\n",
    "\n",
    "# Calculate composite risk score\n",
    "df_processed['Risk_Score'] = (\n",
    "    0.4 * df_processed['Glucose_Normalized'] +\n",
    "    0.3 * df_processed['BMI_Normalized'] + \n",
    "    0.2 * df_processed['Age_Normalized'] +\n",
    "    0.1 * df_processed['BloodPressure_Normalized']\n",
    ")\n",
    "\n",
    "# 6. Interaction features\n",
    "df_processed['BMI_Age_Interaction'] = df_processed['BMI'] * df_processed['Age']\n",
    "df_processed['Glucose_BMI_Interaction'] = df_processed['Glucose'] * df_processed['BMI']\n",
    "\n",
    "print(f\"‚úÖ Created {len([col for col in df_processed.columns if col not in df.columns])} new features\")\n",
    "\n",
    "# Display new features\n",
    "new_features = [col for col in df_processed.columns if col not in df.columns and not col.endswith('_Normalized')]\n",
    "print(f\"New features: {new_features}\")\n",
    "\n",
    "# Show sample of processed data\n",
    "print(f\"\\nüìã Sample of processed data:\")\n",
    "df_processed[['Glucose', 'BMI', 'Age', 'BMI_Category_Num', 'Age_Group_Num', 'Risk_Score', 'Outcome']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0282f746",
   "metadata": {},
   "source": [
    "## üîÑ 4. Data Splitting & Preprocessing\n",
    "\n",
    "Chia d·ªØ li·ªáu v√† chu·∫©n b·ªã cho model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1c0f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"üîÑ DATA SPLITTING & PREPROCESSING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop('Outcome', axis=1)\n",
    "y = df['Outcome']\n",
    "\n",
    "print(f\"üìä Features shape: {X.shape}\")\n",
    "print(f\"üéØ Target shape: {y.shape}\")\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = X.isnull().sum()\n",
    "print(f\"\\nüîç Missing values per feature:\")\n",
    "print(missing_values)\n",
    "\n",
    "# Handle missing values if any\n",
    "if missing_values.sum() > 0:\n",
    "    print(\"\\nüîß Handling missing values with median imputation...\")\n",
    "    imputer = SimpleImputer(strategy='median')\n",
    "    X_imputed = imputer.fit_transform(X)\n",
    "    X = pd.DataFrame(X_imputed, columns=X.columns)\n",
    "else:\n",
    "    print(\"\\n‚úÖ No missing values found\")\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"\\nüìã Data splitting results:\")\n",
    "print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "print(f\"Train class distribution: {y_train.value_counts().to_dict()}\")\n",
    "print(f\"Test class distribution: {y_test.value_counts().to_dict()}\")\n",
    "\n",
    "# Feature scaling\n",
    "print(f\"\\nüîß Feature Scaling:\")\n",
    "scalers = {\n",
    "    'standard': StandardScaler(),\n",
    "    'minmax': MinMaxScaler(),\n",
    "    'robust': RobustScaler()\n",
    "}\n",
    "\n",
    "# We'll use StandardScaler for now\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convert back to DataFrame for easier handling\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X.columns)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X.columns)\n",
    "\n",
    "print(f\"‚úÖ Features scaled using StandardScaler\")\n",
    "print(f\"Training set (scaled): {X_train_scaled.shape}\")\n",
    "print(f\"Test set (scaled): {X_test_scaled.shape}\")\n",
    "\n",
    "# Display scaling statistics\n",
    "print(f\"\\nüìà Original vs Scaled Statistics:\")\n",
    "print(f\"Original - Mean: {X_train.mean().mean():.3f}, Std: {X_train.std().mean():.3f}\")\n",
    "print(f\"Scaled   - Mean: {X_train_scaled.mean().mean():.3f}, Std: {X_train_scaled.std().mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8fdd26",
   "metadata": {},
   "source": [
    "## ü§ñ 5. Model Definition & Configuration\n",
    "\n",
    "ƒê·ªãnh nghƒ©a v√† c·∫•u h√¨nh c√°c machine learning models ƒë·ªÉ training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899ae223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all necessary models\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier, Lasso\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "\n",
    "# Try to import advanced models (might need installation)\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "    XGBOOST_AVAILABLE = True\n",
    "except ImportError:\n",
    "    XGBOOST_AVAILABLE = False\n",
    "    print(\"‚ö†Ô∏è  XGBoost not available, skipping...\")\n",
    "\n",
    "try:\n",
    "    import lightgbm as lgb\n",
    "    LIGHTGBM_AVAILABLE = True\n",
    "except ImportError:\n",
    "    LIGHTGBM_AVAILABLE = False\n",
    "    print(\"‚ö†Ô∏è  LightGBM not available, skipping...\")\n",
    "\n",
    "try:\n",
    "    from catboost import CatBoostClassifier\n",
    "    CATBOOST_AVAILABLE = True\n",
    "except ImportError:\n",
    "    CATBOOST_AVAILABLE = False\n",
    "    print(\"‚ö†Ô∏è  CatBoost not available, skipping...\")\n",
    "\n",
    "print(\"ü§ñ MODEL DEFINITION & CONFIGURATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Define comprehensive model collection\n",
    "models = {}\n",
    "\n",
    "# 1. Linear Models\n",
    "models['Logistic Regression'] = LogisticRegression(random_state=42, max_iter=1000)\n",
    "models['Ridge Classifier'] = RidgeClassifier(random_state=42)\n",
    "models['Linear Discriminant'] = LinearDiscriminantAnalysis()\n",
    "models['Quadratic Discriminant'] = QuadraticDiscriminantAnalysis()\n",
    "\n",
    "# 2. Tree-based Models\n",
    "models['Decision Tree'] = DecisionTreeClassifier(random_state=42)\n",
    "models['Random Forest'] = RandomForestClassifier(\n",
    "    n_estimators=100, random_state=42, n_jobs=-1\n",
    ")\n",
    "models['Extra Trees'] = ExtraTreesClassifier(\n",
    "    n_estimators=100, random_state=42, n_jobs=-1\n",
    ")\n",
    "\n",
    "# 3. Boosting Models\n",
    "models['Gradient Boosting'] = GradientBoostingClassifier(random_state=42)\n",
    "models['AdaBoost'] = AdaBoostClassifier(random_state=42)\n",
    "\n",
    "# 4. Advanced Gradient Boosting (if available)\n",
    "if XGBOOST_AVAILABLE:\n",
    "    models['XGBoost'] = xgb.XGBClassifier(\n",
    "        random_state=42, eval_metric='logloss', verbosity=0\n",
    "    )\n",
    "\n",
    "if LIGHTGBM_AVAILABLE:\n",
    "    models['LightGBM'] = lgb.LGBMClassifier(\n",
    "        random_state=42, verbosity=-1\n",
    "    )\n",
    "\n",
    "if CATBOOST_AVAILABLE:\n",
    "    models['CatBoost'] = CatBoostClassifier(\n",
    "        random_state=42, verbose=False\n",
    "    )\n",
    "\n",
    "# 5. Instance-based Models\n",
    "models['K-Nearest Neighbors'] = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# 6. Kernel Methods\n",
    "models['Support Vector Machine'] = SVC(random_state=42, probability=True)\n",
    "\n",
    "# 7. Probabilistic Models\n",
    "models['Naive Bayes'] = GaussianNB()\n",
    "\n",
    "# 8. Neural Network\n",
    "models['Neural Network'] = MLPClassifier(\n",
    "    hidden_layer_sizes=(100,), random_state=42, max_iter=500\n",
    ")\n",
    "\n",
    "print(f\"üìä Total models configured: {len(models)}\")\n",
    "print(\"\\nüéØ Model Categories:\")\n",
    "print(\"‚Ä¢ Linear Models: 4\")\n",
    "print(\"‚Ä¢ Tree-based Models: 3\") \n",
    "print(\"‚Ä¢ Boosting Models: 2-5 (depending on installations)\")\n",
    "print(\"‚Ä¢ Instance-based: 1\")\n",
    "print(\"‚Ä¢ Kernel Methods: 1\")\n",
    "print(\"‚Ä¢ Probabilistic: 1\")\n",
    "print(\"‚Ä¢ Neural Networks: 1\")\n",
    "\n",
    "print(f\"\\nüìã Available Models:\")\n",
    "for i, (name, model) in enumerate(models.items(), 1):\n",
    "    print(f\"{i:2d}. {name}\")\n",
    "\n",
    "print(f\"\\n‚úÖ All models ready for training!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5833c8a5",
   "metadata": {},
   "source": [
    "## üèãÔ∏è 6. Model Training & Cross-Validation\n",
    "\n",
    "Training t·∫•t c·∫£ models v√† ƒë√°nh gi√° performance b·∫±ng cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea157711",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "import time\n",
    "\n",
    "print(\"üèãÔ∏è MODEL TRAINING & CROSS-VALIDATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Cross-validation setup\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scoring_metrics = ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']\n",
    "\n",
    "# Store results\n",
    "cv_results = {}\n",
    "training_times = {}\n",
    "trained_models = {}\n",
    "\n",
    "print(f\"üîÑ Training {len(models)} models with {cv.n_splits}-fold cross-validation...\")\n",
    "print(\"üìä Metrics: Accuracy, Precision, Recall, F1-Score, ROC-AUC\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Train each model\n",
    "for name, model in models.items():\n",
    "    print(f\"Training {name}...\", end=\" \")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        # Perform cross-validation\n",
    "        scores = {}\n",
    "        for metric in scoring_metrics:\n",
    "            scores[metric] = cross_val_score(\n",
    "                model, X_train_scaled, y_train, \n",
    "                cv=cv, scoring=metric, n_jobs=-1\n",
    "            )\n",
    "        \n",
    "        # Train on full training set for final model\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        trained_models[name] = model\n",
    "        \n",
    "        # Store results\n",
    "        cv_results[name] = scores\n",
    "        training_time = time.time() - start_time\n",
    "        training_times[name] = training_time\n",
    "        \n",
    "        print(f\"‚úÖ ({training_time:.2f}s)\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "        continue\n",
    "\n",
    "print(f\"\\nüìä CROSS-VALIDATION RESULTS SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Create results DataFrame\n",
    "results_df = []\n",
    "for name in cv_results:\n",
    "    row = {'Model': name}\n",
    "    for metric in scoring_metrics:\n",
    "        scores = cv_results[name][metric]\n",
    "        row[f'{metric}_mean'] = scores.mean()\n",
    "        row[f'{metric}_std'] = scores.std()\n",
    "    row['training_time'] = training_times[name]\n",
    "    results_df.append(row)\n",
    "\n",
    "results_df = pd.DataFrame(results_df)\n",
    "\n",
    "# Sort by ROC-AUC score\n",
    "results_df = results_df.sort_values('roc_auc_mean', ascending=False)\n",
    "\n",
    "# Display results\n",
    "print(f\"{'Model':<20} {'Accuracy':<12} {'Precision':<12} {'Recall':<12} {'F1-Score':<12} {'ROC-AUC':<12} {'Time(s)':<8}\")\n",
    "print(\"-\" * 100)\n",
    "\n",
    "for _, row in results_df.iterrows():\n",
    "    name = row['Model']\n",
    "    acc = f\"{row['accuracy_mean']:.3f}¬±{row['accuracy_std']:.3f}\"\n",
    "    prec = f\"{row['precision_mean']:.3f}¬±{row['precision_std']:.3f}\"\n",
    "    rec = f\"{row['recall_mean']:.3f}¬±{row['recall_std']:.3f}\"\n",
    "    f1 = f\"{row['f1_mean']:.3f}¬±{row['f1_std']:.3f}\"\n",
    "    auc = f\"{row['roc_auc_mean']:.3f}¬±{row['roc_auc_std']:.3f}\"\n",
    "    time_str = f\"{row['training_time']:.2f}\"\n",
    "    \n",
    "    print(f\"{name:<20} {acc:<12} {prec:<12} {rec:<12} {f1:<12} {auc:<12} {time_str:<8}\")\n",
    "\n",
    "# Identify top performers\n",
    "print(f\"\\nüèÜ TOP 3 MODELS BY ROC-AUC:\")\n",
    "top_3 = results_df.head(3)\n",
    "for i, (_, row) in enumerate(top_3.iterrows(), 1):\n",
    "    print(f\"{i}. {row['Model']}: {row['roc_auc_mean']:.4f} (¬±{row['roc_auc_std']:.4f})\")\n",
    "\n",
    "print(f\"\\n‚úÖ Training completed! {len(trained_models)} models successfully trained.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a4601d",
   "metadata": {},
   "source": [
    "## üìä 7. Model Evaluation & Visualization\n",
    "\n",
    "ƒê√°nh gi√° chi ti·∫øt performance c·ªßa models tr√™n test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748c4a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"üìä MODEL EVALUATION & VISUALIZATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Evaluate top 3 models on test set\n",
    "top_3_models = results_df.head(3)['Model'].tolist()\n",
    "\n",
    "print(f\"üéØ Evaluating top 3 models on test set:\")\n",
    "for model_name in top_3_models:\n",
    "    print(f\"‚Ä¢ {model_name}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "\n",
    "test_results = {}\n",
    "\n",
    "# Detailed evaluation for each top model\n",
    "for model_name in top_3_models:\n",
    "    print(f\"\\nüîç DETAILED EVALUATION: {model_name}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    model = trained_models[model_name]\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    y_prob = model.predict_proba(X_test_scaled)[:, 1] if hasattr(model, \"predict_proba\") else None\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    if y_prob is not None:\n",
    "        auc_score = roc_auc_score(y_test, y_prob)\n",
    "    else:\n",
    "        auc_score = None\n",
    "    \n",
    "    # Store results\n",
    "    test_results[model_name] = {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'roc_auc': auc_score,\n",
    "        'y_pred': y_pred,\n",
    "        'y_prob': y_prob\n",
    "    }\n",
    "    \n",
    "    # Print metrics\n",
    "    print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"F1-Score:  {f1:.4f}\")\n",
    "    if auc_score:\n",
    "        print(f\"ROC-AUC:   {auc_score:.4f}\")\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(f\"\\nConfusion Matrix:\")\n",
    "    print(f\"              Predicted\")\n",
    "    print(f\"Actual    0    1\")\n",
    "    print(f\"   0    {cm[0,0]:3d}  {cm[0,1]:3d}\")\n",
    "    print(f\"   1    {cm[1,0]:3d}  {cm[1,1]:3d}\")\n",
    "    \n",
    "    # Classification Report\n",
    "    print(f\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Create visualizations\n",
    "print(f\"\\nüìà CREATING PERFORMANCE VISUALIZATIONS\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Set up the plotting style\n",
    "plt.style.use('default')\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "fig.suptitle('Model Performance Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Test Set Accuracy Comparison\n",
    "ax1 = axes[0, 0]\n",
    "model_names = [name for name in top_3_models if name in test_results]\n",
    "accuracies = [test_results[name]['accuracy'] for name in model_names]\n",
    "\n",
    "bars = ax1.bar(range(len(model_names)), accuracies, \n",
    "               color=['#2E86C1', '#28B463', '#F39C12'])\n",
    "ax1.set_title('Test Set Accuracy', fontweight='bold')\n",
    "ax1.set_ylabel('Accuracy')\n",
    "ax1.set_xticks(range(len(model_names)))\n",
    "ax1.set_xticklabels(model_names, rotation=45, ha='right')\n",
    "ax1.set_ylim([0.7, 1.0])\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, (bar, acc) in enumerate(zip(bars, accuracies)):\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "             f'{acc:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# 2. Metrics Comparison\n",
    "ax2 = axes[0, 1]\n",
    "metrics = ['accuracy', 'precision', 'recall', 'f1_score']\n",
    "metric_labels = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
    "\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.25\n",
    "\n",
    "for i, model_name in enumerate(model_names):\n",
    "    if model_name in test_results:\n",
    "        values = [test_results[model_name][metric] for metric in metrics]\n",
    "        ax2.bar(x + i*width, values, width, label=model_name, alpha=0.8)\n",
    "\n",
    "ax2.set_title('Metrics Comparison', fontweight='bold')\n",
    "ax2.set_ylabel('Score')\n",
    "ax2.set_xticks(x + width)\n",
    "ax2.set_xticklabels(metric_labels)\n",
    "ax2.legend()\n",
    "ax2.set_ylim([0.6, 1.0])\n",
    "\n",
    "# 3. ROC Curves\n",
    "ax3 = axes[0, 2]\n",
    "colors = ['#2E86C1', '#28B463', '#F39C12']\n",
    "\n",
    "for i, model_name in enumerate(model_names):\n",
    "    if model_name in test_results and test_results[model_name]['y_prob'] is not None:\n",
    "        y_prob = test_results[model_name]['y_prob']\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "        auc_score = test_results[model_name]['roc_auc']\n",
    "        \n",
    "        ax3.plot(fpr, tpr, color=colors[i], linewidth=2,\n",
    "                label=f'{model_name} (AUC = {auc_score:.3f})')\n",
    "\n",
    "ax3.plot([0, 1], [0, 1], 'k--', alpha=0.6, linewidth=1)\n",
    "ax3.set_title('ROC Curves', fontweight='bold')\n",
    "ax3.set_xlabel('False Positive Rate')\n",
    "ax3.set_ylabel('True Positive Rate')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# 4-6. Confusion Matrices for top 3 models\n",
    "for i, model_name in enumerate(model_names):\n",
    "    ax = axes[1, i]\n",
    "    if model_name in test_results:\n",
    "        cm = confusion_matrix(y_test, test_results[model_name]['y_pred'])\n",
    "        \n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax,\n",
    "                   xticklabels=['No Diabetes', 'Diabetes'],\n",
    "                   yticklabels=['No Diabetes', 'Diabetes'])\n",
    "        ax.set_title(f'Confusion Matrix\\n{model_name}', fontweight='bold')\n",
    "        ax.set_ylabel('Actual')\n",
    "        ax.set_xlabel('Predicted')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"‚úÖ Evaluation completed for {len(test_results)} models!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdca835f",
   "metadata": {},
   "source": [
    "## ‚ö° 8. Hyperparameter Optimization\n",
    "\n",
    "Fine-tuning best performing model ƒë·ªÉ ƒë·∫°t performance t·ªët nh·∫•t."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c4964b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from scipy.stats import randint, uniform\n",
    "import time\n",
    "\n",
    "print(\"‚ö° HYPERPARAMETER OPTIMIZATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Get the best model from previous results\n",
    "best_model_name = results_df.iloc[0]['Model']\n",
    "print(f\"üèÜ Best performing model: {best_model_name}\")\n",
    "print(f\"üìä Current ROC-AUC: {results_df.iloc[0]['roc_auc_mean']:.4f} (¬±{results_df.iloc[0]['roc_auc_std']:.4f})\")\n",
    "\n",
    "# Define parameter grids for different models\n",
    "param_grids = {\n",
    "    'Random Forest': {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [None, 10, 20, 30],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        'max_features': ['sqrt', 'log2']\n",
    "    },\n",
    "    \n",
    "    'Gradient Boosting': {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'subsample': [0.8, 0.9, 1.0]\n",
    "    },\n",
    "    \n",
    "    'Logistic Regression': {\n",
    "        'C': [0.01, 0.1, 1, 10, 100],\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'solver': ['liblinear', 'saga']\n",
    "    },\n",
    "    \n",
    "    'Support Vector Machine': {\n",
    "        'C': [0.1, 1, 10, 100],\n",
    "        'gamma': ['scale', 'auto', 0.001, 0.01, 0.1, 1],\n",
    "        'kernel': ['rbf', 'linear', 'poly']\n",
    "    },\n",
    "    \n",
    "    'Neural Network': {\n",
    "        'hidden_layer_sizes': [(50,), (100,), (100, 50), (200,), (100, 100)],\n",
    "        'alpha': [0.0001, 0.001, 0.01],\n",
    "        'learning_rate_init': [0.001, 0.01, 0.1]\n",
    "    }\n",
    "}\n",
    "\n",
    "# XGBoost parameters (if available)\n",
    "if XGBOOST_AVAILABLE and 'XGBoost' in param_grids:\n",
    "    param_grids['XGBoost'] = {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'subsample': [0.8, 0.9, 1.0],\n",
    "        'colsample_bytree': [0.8, 0.9, 1.0]\n",
    "    }\n",
    "\n",
    "# Check if parameter grid exists for best model\n",
    "if best_model_name not in param_grids:\n",
    "    print(f\"‚ö†Ô∏è  No parameter grid defined for {best_model_name}\")\n",
    "    print(\"Using default parameters...\")\n",
    "    optimized_model = trained_models[best_model_name]\n",
    "    optimization_time = 0\n",
    "    best_params = \"Default parameters\"\n",
    "    best_cv_score = results_df.iloc[0]['roc_auc_mean']\n",
    "    \n",
    "else:\n",
    "    print(f\"\\nüîç Optimizing hyperparameters for {best_model_name}...\")\n",
    "    print(f\"üìã Parameter grid size: {np.prod([len(v) for v in param_grids[best_model_name].values()])} combinations\")\n",
    "    \n",
    "    # Get base model\n",
    "    base_model = None\n",
    "    for name, model in models.items():\n",
    "        if name == best_model_name:\n",
    "            # Create a fresh instance of the model\n",
    "            base_model = type(model)(**{k: v for k, v in model.get_params().items() \n",
    "                                       if k not in param_grids[best_model_name]})\n",
    "            break\n",
    "    \n",
    "    if base_model is None:\n",
    "        print(f\"‚ùå Could not create base model for {best_model_name}\")\n",
    "        optimized_model = trained_models[best_model_name]\n",
    "    else:\n",
    "        # Use RandomizedSearchCV for efficiency\n",
    "        print(\"üé≤ Using RandomizedSearchCV for efficiency (100 iterations)...\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Randomized search\n",
    "        random_search = RandomizedSearchCV(\n",
    "            estimator=base_model,\n",
    "            param_distributions=param_grids[best_model_name],\n",
    "            n_iter=100,  # Try 100 random combinations\n",
    "            cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "            scoring='roc_auc',\n",
    "            n_jobs=-1,\n",
    "            random_state=42,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        # Fit the search\n",
    "        random_search.fit(X_train_scaled, y_train)\n",
    "        \n",
    "        optimization_time = time.time() - start_time\n",
    "        \n",
    "        # Get results\n",
    "        optimized_model = random_search.best_estimator_\n",
    "        best_params = random_search.best_params_\n",
    "        best_cv_score = random_search.best_score_\n",
    "        \n",
    "        print(f\"\\n‚úÖ Optimization completed in {optimization_time:.2f} seconds!\")\n",
    "\n",
    "# Evaluate optimized model\n",
    "print(f\"\\nüéØ OPTIMIZED MODEL EVALUATION\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "print(f\"Best CV ROC-AUC: {best_cv_score:.4f}\")\n",
    "\n",
    "# Test set evaluation\n",
    "y_pred_optimized = optimized_model.predict(X_test_scaled)\n",
    "y_prob_optimized = optimized_model.predict_proba(X_test_scaled)[:, 1] if hasattr(optimized_model, \"predict_proba\") else None\n",
    "\n",
    "# Calculate metrics\n",
    "test_accuracy = accuracy_score(y_test, y_pred_optimized)\n",
    "test_precision = precision_score(y_test, y_pred_optimized)\n",
    "test_recall = recall_score(y_test, y_pred_optimized)\n",
    "test_f1 = f1_score(y_test, y_pred_optimized)\n",
    "test_auc = roc_auc_score(y_test, y_prob_optimized) if y_prob_optimized is not None else None\n",
    "\n",
    "print(f\"\\nüìä Test Set Performance (Optimized):\")\n",
    "print(f\"Accuracy:  {test_accuracy:.4f}\")\n",
    "print(f\"Precision: {test_precision:.4f}\")\n",
    "print(f\"Recall:    {test_recall:.4f}\")\n",
    "print(f\"F1-Score:  {test_f1:.4f}\")\n",
    "if test_auc:\n",
    "    print(f\"ROC-AUC:   {test_auc:.4f}\")\n",
    "\n",
    "# Compare with original model\n",
    "if best_model_name in test_results:\n",
    "    original_auc = test_results[best_model_name]['roc_auc']\n",
    "    if test_auc and original_auc:\n",
    "        improvement = test_auc - original_auc\n",
    "        print(f\"\\nüìà Improvement over original model:\")\n",
    "        print(f\"ROC-AUC: {original_auc:.4f} ‚Üí {test_auc:.4f} ({improvement:+.4f})\")\n",
    "        \n",
    "        if improvement > 0:\n",
    "            print(\"‚úÖ Optimization successful!\")\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è  No significant improvement - original model was already well-tuned\")\n",
    "\n",
    "print(f\"\\nüèÜ FINAL OPTIMIZED MODEL: {best_model_name}\")\n",
    "final_model = optimized_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16811c3",
   "metadata": {},
   "source": [
    "## üíæ 9. Model Selection & Export\n",
    "\n",
    "L∆∞u model t·ªët nh·∫•t v√† chu·∫©n b·ªã cho production deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c645b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pickle\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"üíæ MODEL SELECTION & EXPORT\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create models directory if it doesn't exist\n",
    "models_dir = \"../models\"\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "\n",
    "# Prepare model metadata\n",
    "model_metadata = {\n",
    "    \"model_name\": best_model_name,\n",
    "    \"model_type\": type(final_model).__name__,\n",
    "    \"training_date\": datetime.now().isoformat(),\n",
    "    \"dataset_info\": {\n",
    "        \"source\": \"Pima Indians Diabetes Dataset (Cleaned)\",\n",
    "        \"features\": list(X.columns),\n",
    "        \"n_samples\": len(df),\n",
    "        \"n_features\": len(X.columns),\n",
    "        \"target_distribution\": df['Outcome'].value_counts().to_dict()\n",
    "    },\n",
    "    \"performance_metrics\": {\n",
    "        \"cv_roc_auc_mean\": float(best_cv_score),\n",
    "        \"test_accuracy\": float(test_accuracy),\n",
    "        \"test_precision\": float(test_precision),\n",
    "        \"test_recall\": float(test_recall),\n",
    "        \"test_f1_score\": float(test_f1),\n",
    "        \"test_roc_auc\": float(test_auc) if test_auc else None\n",
    "    },\n",
    "    \"hyperparameters\": str(best_params),\n",
    "    \"preprocessing\": {\n",
    "        \"scaler\": \"StandardScaler\",\n",
    "        \"missing_value_strategy\": \"median_imputation\"\n",
    "    },\n",
    "    \"feature_names\": list(X.columns),\n",
    "    \"feature_importance\": None  # Will be filled if model supports it\n",
    "}\n",
    "\n",
    "# Get feature importance if available\n",
    "if hasattr(final_model, 'feature_importances_'):\n",
    "    feature_importance = dict(zip(X.columns, final_model.feature_importances_))\n",
    "    model_metadata[\"feature_importance\"] = {k: float(v) for k, v in feature_importance.items()}\n",
    "    \n",
    "    print(f\"üìä Feature Importance (Top 5):\")\n",
    "    sorted_features = sorted(feature_importance.items(), key=lambda x: x[1], reverse=True)\n",
    "    for i, (feature, importance) in enumerate(sorted_features[:5]):\n",
    "        print(f\"{i+1}. {feature}: {importance:.4f}\")\n",
    "\n",
    "elif hasattr(final_model, 'coef_'):\n",
    "    feature_importance = dict(zip(X.columns, abs(final_model.coef_[0])))\n",
    "    model_metadata[\"feature_importance\"] = {k: float(v) for k, v in feature_importance.items()}\n",
    "    \n",
    "    print(f\"üìä Feature Coefficients (Top 5 by absolute value):\")\n",
    "    sorted_features = sorted(feature_importance.items(), key=lambda x: x[1], reverse=True)\n",
    "    for i, (feature, coef) in enumerate(sorted_features[:5]):\n",
    "        print(f\"{i+1}. {feature}: {coef:.4f}\")\n",
    "\n",
    "# Save the model\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "model_filename = f\"diabetes_model_{best_model_name.lower().replace(' ', '_')}_{timestamp}.joblib\"\n",
    "model_path = os.path.join(models_dir, model_filename)\n",
    "\n",
    "print(f\"\\nüíæ Saving model to: {model_path}\")\n",
    "joblib.dump(final_model, model_path)\n",
    "\n",
    "# Save the scaler\n",
    "scaler_filename = f\"scaler_{timestamp}.joblib\"\n",
    "scaler_path = os.path.join(models_dir, scaler_filename)\n",
    "joblib.dump(scaler, scaler_path)\n",
    "\n",
    "# Save model metadata\n",
    "metadata_filename = f\"model_metadata_{timestamp}.json\"\n",
    "metadata_path = os.path.join(models_dir, metadata_filename)\n",
    "with open(metadata_path, 'w') as f:\n",
    "    json.dump(model_metadata, f, indent=2)\n",
    "\n",
    "print(f\"‚úÖ Model saved: {model_filename}\")\n",
    "print(f\"‚úÖ Scaler saved: {scaler_filename}\")\n",
    "print(f\"‚úÖ Metadata saved: {metadata_filename}\")\n",
    "\n",
    "# Create a simple production-ready model class\n",
    "production_model_code = f'''\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Union, List, Dict\n",
    "\n",
    "class DiabetesPredictor:\n",
    "    \"\"\"\n",
    "    Production-ready diabetes prediction model.\n",
    "    \n",
    "    Features expected (in order):\n",
    "    {list(X.columns)}\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model_path: str, scaler_path: str):\n",
    "        \"\"\"Initialize the predictor with model and scaler paths.\"\"\"\n",
    "        self.model = joblib.load(model_path)\n",
    "        self.scaler = joblib.load(scaler_path)\n",
    "        self.feature_names = {list(X.columns)}\n",
    "        \n",
    "    def predict(self, data: Union[Dict, List[Dict], pd.DataFrame, np.ndarray]) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Predict diabetes probability.\n",
    "        \n",
    "        Args:\n",
    "            data: Input features as dict, list of dicts, DataFrame, or numpy array\n",
    "            \n",
    "        Returns:\n",
    "            numpy array of predictions (0 or 1)\n",
    "        \"\"\"\n",
    "        processed_data = self._preprocess_input(data)\n",
    "        return self.model.predict(processed_data)\n",
    "    \n",
    "    def predict_proba(self, data: Union[Dict, List[Dict], pd.DataFrame, np.ndarray]) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Predict diabetes probabilities.\n",
    "        \n",
    "        Args:\n",
    "            data: Input features as dict, list of dicts, DataFrame, or numpy array\n",
    "            \n",
    "        Returns:\n",
    "            numpy array of probabilities [prob_no_diabetes, prob_diabetes]\n",
    "        \"\"\"\n",
    "        processed_data = self._preprocess_input(data)\n",
    "        if hasattr(self.model, 'predict_proba'):\n",
    "            return self.model.predict_proba(processed_data)\n",
    "        else:\n",
    "            # Fallback for models without predict_proba\n",
    "            pred = self.model.predict(processed_data)\n",
    "            return np.column_stack([1-pred, pred])\n",
    "    \n",
    "    def _preprocess_input(self, data: Union[Dict, List[Dict], pd.DataFrame, np.ndarray]) -> np.ndarray:\n",
    "        \"\"\"Preprocess input data to match training format.\"\"\"\n",
    "        if isinstance(data, dict):\n",
    "            data = [data]\n",
    "        \n",
    "        if isinstance(data, list):\n",
    "            df = pd.DataFrame(data)\n",
    "        elif isinstance(data, pd.DataFrame):\n",
    "            df = data.copy()\n",
    "        elif isinstance(data, np.ndarray):\n",
    "            df = pd.DataFrame(data, columns=self.feature_names)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported data type\")\n",
    "        \n",
    "        # Ensure all required features are present\n",
    "        for feature in self.feature_names:\n",
    "            if feature not in df.columns:\n",
    "                raise ValueError(f\"Missing required feature: {{feature}}\")\n",
    "        \n",
    "        # Select and order features correctly\n",
    "        df = df[self.feature_names]\n",
    "        \n",
    "        # Scale the features\n",
    "        scaled_data = self.scaler.transform(df)\n",
    "        \n",
    "        return scaled_data\n",
    "\n",
    "# Example usage:\n",
    "# predictor = DiabetesPredictor('path/to/model.joblib', 'path/to/scaler.joblib')\n",
    "# result = predictor.predict({{\"Pregnancies\": 1, \"Glucose\": 120, \"BloodPressure\": 70, ...}})\n",
    "# probabilities = predictor.predict_proba({{\"Pregnancies\": 1, \"Glucose\": 120, ...}})\n",
    "'''\n",
    "\n",
    "# Save the production model class\n",
    "production_file = os.path.join(models_dir, f\"diabetes_predictor_{timestamp}.py\")\n",
    "with open(production_file, 'w') as f:\n",
    "    f.write(production_model_code)\n",
    "\n",
    "print(f\"‚úÖ Production model class saved: diabetes_predictor_{timestamp}.py\")\n",
    "\n",
    "# Test the saved model by loading and making a prediction\n",
    "print(f\"\\nüß™ Testing saved model...\")\n",
    "loaded_model = joblib.load(model_path)\n",
    "loaded_scaler = joblib.load(scaler_path)\n",
    "\n",
    "# Create a test sample\n",
    "test_sample = X_test_scaled.iloc[0:1]  # First test sample\n",
    "test_prediction = loaded_model.predict(test_sample)\n",
    "test_probability = loaded_model.predict_proba(test_sample)[0][1] if hasattr(loaded_model, 'predict_proba') else None\n",
    "\n",
    "print(f\"‚úÖ Model loaded successfully!\")\n",
    "print(f\"Test prediction: {test_prediction[0]} (probability: {test_probability:.3f})\" if test_probability else f\"Test prediction: {test_prediction[0]}\")\n",
    "\n",
    "# Summary\n",
    "print(f\"\\nüéâ MODEL TRAINING COMPLETED SUCCESSFULLY!\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"üèÜ Best Model: {best_model_name}\")\n",
    "print(f\"üìä Test ROC-AUC: {test_auc:.4f}\" if test_auc else f\"üìä Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"üìÅ Files saved in: {models_dir}/\")\n",
    "print(f\"   ‚Ä¢ Model: {model_filename}\")\n",
    "print(f\"   ‚Ä¢ Scaler: {scaler_filename}\")\n",
    "print(f\"   ‚Ä¢ Metadata: {metadata_filename}\")\n",
    "print(f\"   ‚Ä¢ Production code: diabetes_predictor_{timestamp}.py\")\n",
    "print(f\"\\nüí° Ready for integration with backend API!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3866e7d4",
   "metadata": {},
   "source": [
    "## üéâ Pipeline Ho√†n Th√†nh!\n",
    "\n",
    "### üìä T·ªïng k·∫øt quy tr√¨nh:\n",
    "1. ‚úÖ Load v√† explore cleaned dataset\n",
    "2. ‚úÖ Feature engineering v√† preprocessing  \n",
    "3. ‚úÖ Train/test split\n",
    "4. ‚úÖ Define v√† train 11 ML models\n",
    "5. ‚úÖ Evaluate v√† compare models\n",
    "6. ‚úÖ Hyperparameter tuning model t·ªët nh·∫•t\n",
    "7. ‚úÖ Final evaluation v√† model selection\n",
    "8. ‚úÖ Save model cho production\n",
    "\n",
    "### üèÜ Model ƒë√£ ƒë∆∞·ª£c l∆∞u v√†o:\n",
    "- `../models/best_diabetes_model.pkl` - Model t·ªët nh·∫•t\n",
    "- `../models/scaler.pkl` - Scaler ƒë·ªÉ preprocess input\n",
    "- `../models/model_metadata.json` - Th√¥ng tin v·ªÅ model\n",
    "\n",
    "### üöÄ S·ª≠ d·ª•ng model:\n",
    "\n",
    "```python\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "# Load model\n",
    "model = joblib.load('../models/best_diabetes_model.pkl')\n",
    "scaler = joblib.load('../models/scaler.pkl')\n",
    "\n",
    "# Example prediction\n",
    "sample_input = np.array([[6, 148, 72, 35, 0, 33.6, 0.627, 50]])\n",
    "sample_scaled = scaler.transform(sample_input)\n",
    "prediction = model.predict(sample_scaled)\n",
    "probability = model.predict_proba(sample_scaled)\n",
    "\n",
    "print(f\"Prediction: {'Diabetes' if prediction[0] == 1 else 'No Diabetes'}\")\n",
    "print(f\"Probability: {probability[0][1]:.2%}\")\n",
    "```\n",
    "\n",
    "### üìà Next Steps:\n",
    "1. Integrate model v√†o Backend API\n",
    "2. Deploy model l√™n server\n",
    "3. T·∫°o monitoring system ƒë·ªÉ track model performance\n",
    "4. Setup retraining pipeline v·ªõi data m·ªõi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
